# Feature Opportunities for the Rodex Platform

The following concepts build on the repository's existing planner, automation, and deployment workflows. Each section outlines why the investment matters, the implementation building blocks that already exist in the codebase, and the measurable outcomes that signal success.

## 1. Automated Template Update Validation Pipeline

**Problem**
- Updatable Railway templates can introduce regressions when upstream authors push changes, yet there is no automated safety net before merging the generated pull requests.

**Solution Overview**
- Leverage the automation service scaffold (`services/automation/main.py`) to execute smoke tests whenever Railway opens an update branch. 【F:services/automation/main.py†L1-L55】
- Package Playwright or API-level checks covering the planner and landing endpoints described in the README deployment walkthrough. 【F:README.md†L31-L58】

**Implementation Plan**
1. Extend the automation service entry point with a command runner that can execute scripted validations against the deployed preview environment.
2. Configure Railway PR deploys to invoke the automation runner and capture pass/fail signals.
3. Publish GitHub Check annotations summarising the test matrix, storing full logs and screenshots in object storage for debugging.

**Dependencies & Considerations**
- Requires provisioning credentials for preview environments and secure storage for artifacts.
- Playwright adds CI runtime cost; invest in a minimal deterministic suite to keep feedback fast.

**Success Metrics**
- 100% of template update PRs receive automated validation results.
- Mean review time for update PRs decreases because maintainers can rely on the signal.

## 2. Gemini Streaming Observability Dashboard

**Problem**
- Gemini streaming reliability is highlighted as an operational risk, yet engineers lack unified telemetry to diagnose retries, heartbeat failures, or endpoint failovers. 【F:README.md†L4-L16】

**Solution Overview**
- Instrument the existing streaming client (`services/planner/gemini_stream.py`) to emit metrics and structured events describing retry attempts, fallback usage, and latency distribution. 【F:services/planner/gemini_stream.py†L21-L221】
- Centralise configuration for observability sinks within the planner settings module. 【F:services/planner/project_settings.py†L1-L114】

**Implementation Plan**
1. Add counters and histograms to the Gemini streaming client, forwarding data to a metrics backend (e.g., OpenTelemetry exporters).
2. Introduce tracing around prompt planning flows to correlate streaming degradation with downstream automation triggers.
3. Build a lightweight dashboard (Grafana or DataDog) and alerting rules keyed on retry spikes or sustained fallback usage.

**Dependencies & Considerations**
- Ensure instrumentation is asynchronous to avoid blocking the streaming loop.
- Align metric naming with existing observability conventions to simplify adoption.

**Success Metrics**
- Time-to-detect streaming incidents drops due to actionable dashboards.
- Post-incident reviews cite dashboard insights when identifying root causes.

## 3. Landing Prompt-to-Execution Feedback Loop

**Problem**
- The landing API currently holds prompts in memory (`services/planner/landing_api.py`), leaving users without visibility into automation progress once a `job_id` is issued. 【F:services/planner/landing_api.py†L1-L216】

**Solution Overview**
- Persist prompt submissions to a durable store keyed by `job_id` and link them with downstream automation workflows handled by the planner.
- Stream progress updates back to clients through server-sent events (SSE) or WebSocket endpoints.

**Implementation Plan**
1. Introduce a storage adapter (Redis or Postgres) for prompt submissions and job metadata, encapsulated behind the planner service boundary.
2. When automation tasks execute, publish lifecycle events (queued, running, succeeded, failed) that the landing API can relay to subscribers.
3. Update the frontend to display real-time progress, including diff previews or artifact links generated by automation jobs.

**Dependencies & Considerations**
- Requires authentication and rate limiting to prevent abuse of real-time endpoints.
- Ensure data retention policies for prompt history align with privacy expectations.

**Success Metrics**
- Users receive immediate feedback on automation status without manual refresh.
- Support volume drops as customers self-serve via transparent execution tracking.
